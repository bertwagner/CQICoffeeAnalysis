{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37232bitvenvvirtualenv21d882e9f719476aaee9957a5bb220cc",
   "display_name": "Python 3.7.2 32-bit ('.venv': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Setup defaults and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(17)\n",
    "\n",
    "# change plot defaults\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=10)\n",
    "mpl.rc('xtick', labelsize=8)\n",
    "mpl.rc('ytick', labelsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_data = pd.read_csv(\"datasets//arabica_data_cleaned.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create test and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set =  train_test_split(coffee_data, test_size=0.2, random_state=17)\n",
    "\n",
    "coffee = train_set.drop(\"Total.Cup.Points\",axis=1)\n",
    "coffee_labels = train_set[\"Total.Cup.Points\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keep only the columns we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = coffee[[\"Country.of.Origin\", \"Variety\", \"Processing.Method\", \"altitude_mean_meters\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Remove altitudes less than 200 meters and fill in with median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee[coffee[\"altitude_mean_meters\"] < 200] = None\n",
    "\n",
    "altitude_median = coffee[\"altitude_mean_meters\"].median()\n",
    "coffee[\"altitude_mean_meters\"].fillna(altitude_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drop rows with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_rows_dropped =coffee.dropna()\n",
    "\n",
    "dropped_row_indexes = coffee[~coffee.index.isin(coffee_rows_dropped.index)]\n",
    "dropped_row_indexes = dropped_row_indexes.index.values.tolist()\n",
    "coffee = coffee_rows_dropped.reset_index(drop=True)\n",
    "coffee_labels = coffee_labels.drop(dropped_row_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encode categories to numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder_country_of_origin = OrdinalEncoder()\n",
    "country_of_origin_encoded = ordinal_encoder_country_of_origin.fit_transform(coffee[[\"Country.of.Origin\"]])\n",
    "encoded_country_of_origin = pd.DataFrame(data=country_of_origin_encoded, columns=[\"country_of_origin_encoded\"])\n",
    "coffee = coffee.merge(encoded_country_of_origin,left_index=True,right_index=True) \n",
    "\n",
    "ordinal_encoder_processing_method = OrdinalEncoder()\n",
    "processing_method_encoded = ordinal_encoder_processing_method.fit_transform(coffee[[\"Processing.Method\"]])\n",
    "encoded_processing_method = pd.DataFrame(data=processing_method_encoded, columns=[\"processing_method_encoded\"])\n",
    "coffee = coffee.merge(encoded_processing_method,left_index=True,right_index=True) \n",
    "\n",
    "ordinal_encoder_variety = OrdinalEncoder()\n",
    "variety_encoded = ordinal_encoder_variety.fit_transform(coffee[[\"Variety\"]])\n",
    "encoded_variety = pd.DataFrame(data=variety_encoded, columns=[\"variety_encoded\"])\n",
    "coffee = coffee.merge(encoded_variety,left_index=True,right_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale the data and build prepared training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "coffee_num = coffee[[\"altitude_mean_meters\",\"processing_method_encoded\",\"variety_encoded\"]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "coffee_num_scaled = scaler.fit_transform(coffee_num)\n",
    "\n",
    "coffee_prepared = np.concatenate([coffee_num_scaled,coffee[[\"country_of_origin_encoded\"]].values], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train on the prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(coffee_prepared, coffee_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test some of the trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Predictions: [81.51293136 82.43912883 82.26316622 82.28568892 81.33942282 82.67052366\n 81.93818105 81.43489021 82.24943436 82.59114624]\nLabels: [81.75, 82.17, 83.75, 84.67, 81.92, 78.42, 79.0, 79.0, 86.0, 82.42]\n"
    }
   ],
   "source": [
    "sample_data = coffee_prepared[:10]\n",
    "sample_labels = coffee_labels.iloc[:10]\n",
    "print(\"Predictions:\",linear_regression.predict(sample_data))\n",
    "print(\"Labels:\", list(sample_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate the root mean squared errors for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2.600758224259066"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "coffee_predictions = linear_regression.predict(coffee_prepared)\n",
    "linear_mse = mean_squared_error(coffee_labels,coffee_predictions)\n",
    "linear_rmse = np.sqrt(linear_mse)\n",
    "linear_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Try a decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.5703257562939459"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(coffee_prepared, coffee_labels)\n",
    "\n",
    "coffee_predictions = tree_reg.predict(coffee_prepared)\n",
    "tree_mse = mean_squared_error(coffee_labels,coffee_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K-fold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Scores: [3.30898163 2.09468036 2.58532742 2.2444926  3.05385241 3.03027305\n 3.07314405 2.28117444 2.62030636 2.93115609]\nMean: 2.7223388414111245\nStandard deviation: 0.39517646666621703\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, coffee_prepared, coffee_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Scores: [3.14457703 1.88255198 2.2647137  2.82786659 2.74007018 2.53324578\n 3.28570511 2.1970685  2.71576122 2.19749747]\nMean: 2.5789057563632234\nStandard deviation: 0.42464293689168886\n"
    }
   ],
   "source": [
    "scores = cross_val_score(linear_regression, coffee_prepared, coffee_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1.6777201028631585"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(coffee_prepared, coffee_labels)\n",
    "\n",
    "coffee_predictions = forest_reg.predict(coffee_prepared)\n",
    "forest_mse = mean_squared_error(coffee_labels,coffee_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Scores: [2.8888984  2.01233259 2.49639533 2.29937942 2.93265467 2.59838345\n 2.85962389 1.90371663 2.49853375 2.38031552]\nMean: 2.4870233643473663\nStandard deviation: 0.33521906968735005\n"
    }
   ],
   "source": [
    "scores = cross_val_score(forest_reg, coffee_prepared, coffee_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perform a grid search for hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_features': 1, 'n_estimators': 70}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30,70,100,150], 'max_features': [1,2,3,4]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10, 30,70,100,150], 'max_features': [1,2,3,4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=17)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(coffee_prepared, coffee_labels)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.569480977152115 {'max_features': 1, 'n_estimators': 3}\n2.490407331411389 {'max_features': 1, 'n_estimators': 10}\n2.466321649750459 {'max_features': 1, 'n_estimators': 30}\n2.448460584692986 {'max_features': 1, 'n_estimators': 70}\n2.4534395217053464 {'max_features': 1, 'n_estimators': 100}\n2.4513612104363163 {'max_features': 1, 'n_estimators': 150}\n2.632720485157431 {'max_features': 2, 'n_estimators': 3}\n2.498671403564893 {'max_features': 2, 'n_estimators': 10}\n2.4815571864675956 {'max_features': 2, 'n_estimators': 30}\n2.458334479092535 {'max_features': 2, 'n_estimators': 70}\n2.4615362402031216 {'max_features': 2, 'n_estimators': 100}\n2.456932294939917 {'max_features': 2, 'n_estimators': 150}\n2.6018028444473758 {'max_features': 3, 'n_estimators': 3}\n2.515790158251999 {'max_features': 3, 'n_estimators': 10}\n2.485912987915155 {'max_features': 3, 'n_estimators': 30}\n2.4674612833219247 {'max_features': 3, 'n_estimators': 70}\n2.4707955443109997 {'max_features': 3, 'n_estimators': 100}\n2.465740027050367 {'max_features': 3, 'n_estimators': 150}\n2.594532365576551 {'max_features': 4, 'n_estimators': 3}\n2.513581912114573 {'max_features': 4, 'n_estimators': 10}\n2.492515139057924 {'max_features': 4, 'n_estimators': 30}\n2.478558702296716 {'max_features': 4, 'n_estimators': 70}\n2.4869659792988807 {'max_features': 4, 'n_estimators': 100}\n2.4805090055881167 {'max_features': 4, 'n_estimators': 150}\n2.6186131187911332 {'bootstrap': False, 'max_features': 1, 'n_estimators': 3}\n2.5773182445814 {'bootstrap': False, 'max_features': 1, 'n_estimators': 10}\n2.555484174281545 {'bootstrap': False, 'max_features': 1, 'n_estimators': 30}\n2.552947949217125 {'bootstrap': False, 'max_features': 1, 'n_estimators': 70}\n2.55528259397866 {'bootstrap': False, 'max_features': 1, 'n_estimators': 100}\n2.5557398429437455 {'bootstrap': False, 'max_features': 1, 'n_estimators': 150}\n2.625530895248776 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n2.594690821899312 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n2.574925391392791 {'bootstrap': False, 'max_features': 2, 'n_estimators': 30}\n2.5690595585810794 {'bootstrap': False, 'max_features': 2, 'n_estimators': 70}\n2.5675891895236904 {'bootstrap': False, 'max_features': 2, 'n_estimators': 100}\n2.5682995614118718 {'bootstrap': False, 'max_features': 2, 'n_estimators': 150}\n2.6736622965596295 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n2.63376771435753 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n2.6076197609648433 {'bootstrap': False, 'max_features': 3, 'n_estimators': 30}\n2.6070330624160816 {'bootstrap': False, 'max_features': 3, 'n_estimators': 70}\n2.6074592916513657 {'bootstrap': False, 'max_features': 3, 'n_estimators': 100}\n2.6052965506178145 {'bootstrap': False, 'max_features': 3, 'n_estimators': 150}\n2.774028847425562 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n2.7737255195493336 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n2.7724177580744254 {'bootstrap': False, 'max_features': 4, 'n_estimators': 30}\n2.769767586857451 {'bootstrap': False, 'max_features': 4, 'n_estimators': 70}\n2.7702371853974657 {'bootstrap': False, 'max_features': 4, 'n_estimators': 100}\n2.7700912289872455 {'bootstrap': False, 'max_features': 4, 'n_estimators': 150}\n"
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.47685044, 0.06747558, 0.18630188, 0.26937209])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "#[\"altitude\",\"processing\",\"variety\",\"country\"]\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The above feature importance indicates that altitude has the largest importance, followed by country of origin, variety, and finally processing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = train_set.drop(\"Total.Cup.Points\",axis=1)\n",
    "y_test = train_set[\"Total.Cup.Points\"].copy()\n",
    "\n",
    "# need to solve this pipeline issue!!! put all transforms into functions?\n",
    "X_test_prepared = #full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  }
 ]
}